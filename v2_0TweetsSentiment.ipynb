{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "MF4bweVsXU57"
      },
      "outputs": [],
      "source": [
        "from keras.datasets import imdb\n",
        "from keras.preprocessing import sequence\n",
        "import keras\n",
        "import tensorflow as tf\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import sklearn\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 246
        },
        "id": "4OLvuvckvNOX",
        "outputId": "a5eb3c70-00e0-4fbe-d00e-b035f1164224"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-8c479931-dd42-4ecf-b96c-b0467369acd1\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-8c479931-dd42-4ecf-b96c-b0467369acd1\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving test_labels.txt to test_labels.txt\n",
            "Saving test_text.txt to test_text.txt\n",
            "Saving train_labels.txt to train_labels.txt\n",
            "Saving train_text.txt to train_text.txt\n",
            "Saving val_labels.txt to val_labels.txt\n",
            "Saving val_text.txt to val_text.txt\n"
          ]
        }
      ],
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_tweeteval_split(text_path, label_path):\n",
        "    \"\"\"Loads TweetEval split data from text and label files.\"\"\"\n",
        "    with open(text_path, 'r', encoding='utf-8') as f:\n",
        "        text_data = [line.strip() for line in f]\n",
        "    with open(label_path, 'r', encoding='utf-8') as f:\n",
        "        label_data = [int(line.strip()) for line in f] # Assuming labels are integers\n",
        "\n",
        "    df = pd.DataFrame({'text': text_data, 'label': label_data})\n",
        "    return df\n",
        "\n",
        "# Load TweetEval Sentiment splits\n",
        "df_train = load_tweeteval_split('train_text.txt', 'train_labels.txt')\n",
        "df_val = load_tweeteval_split('val_text.txt', 'val_labels.txt')\n",
        "df_test = load_tweeteval_split('test_text.txt', 'test_labels.txt')\n",
        "\n",
        "print(\"Training data shape:\", df_train.shape)\n",
        "print(\"Validation data shape:\", df_val.shape)\n",
        "print(\"Testing data shape:\", df_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "un1ow-wD-PM2",
        "outputId": "9e0853cc-2c9e-4719-8de4-23202a123e46"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training data shape: (45615, 2)\n",
            "Validation data shape: (2000, 2)\n",
            "Testing data shape: (12284, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Combine train and val sets for better training\n",
        "df = pd.concat([df_train, df_val], ignore_index=True)\n",
        "\n",
        "print(\"Dataset Size:\", len(df))\n",
        "print(df['label'].value_counts())\n",
        "print(df.head())\n",
        "print(df.tail())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IoGGNvLU_0vd",
        "outputId": "b8219127-c86d-439d-fca7-9cfd0571be05"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset Size: 47615\n",
            "label\n",
            "1    21542\n",
            "2    18668\n",
            "0     7405\n",
            "Name: count, dtype: int64\n",
            "                                                text  label\n",
            "0  \"QT @user In the original draft of the 7th boo...      2\n",
            "1  \"Ben Smith / Smith (concussion) remains out of...      1\n",
            "2  Sorry bout the stream last night I crashed out...      1\n",
            "3  Chase Headley's RBI double in the 8th inning o...      1\n",
            "4  @user Alciato: Bee will invest 150 million in ...      2\n",
            "                                                    text  label\n",
            "47610  \"LONDON (AP) \"\" Prince George celebrates his s...      1\n",
            "47611  Harper's Worst Offense against Refugees may be...      1\n",
            "47612  Hold on... Sam Smith may do the theme to Spect...      2\n",
            "47613  Gonna watch Final Destination 5 tonight. I alw...      1\n",
            "47614  \"Interview with Devon Alexander \\\"\"\"\"Speed Kil...      1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train-Test Split\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X = df['text']  # input features — tweet texts\n",
        "y = df['label'] # target labels — encoded sentiment values (0 -> negative, 1 -> neutral, 2-> positive)\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X, y, test_size=0.15, random_state=42)"
      ],
      "metadata": {
        "id": "9FaoDCewB_bS"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qhgV2eF9yBQK",
        "outputId": "6c1b2854-dfe6-4753-fbfb-91a3e000b981"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(40472, 10000)\n",
            "(7143, 10000)\n"
          ]
        }
      ],
      "source": [
        "# Training the Model (using TF-IDF + Logistic Regression)\n",
        "\n",
        "# Vectorize the Text (TF-IDF)\n",
        "# TF-IDF — Term Frequency–Inverse Document Frequency\n",
        "# TF (Term Frequency): how often a word appears in a document\n",
        "# IDF (Inverse Document Frequency): how rare the word is across all documents\n",
        "# Common words (like \"the\", \"and\") appear in many documents and get lower scores\n",
        "# Uncommon but meaningful words get higher scores\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "# This imports a tool that converts text into numeric feature vectors using the TF-IDF method\n",
        "\n",
        "vectorizer = TfidfVectorizer(max_features=10000)\n",
        "# Only keeps the top 10,000 most important words (based on TF-IDF score)\n",
        "# This reduces dimensionality and speeds up training\n",
        "X_train_vec = vectorizer.fit_transform(X_train)\n",
        "# This fit the vectorizer and transform training data\n",
        "# Learns the vocabulary and computes TF-IDF scores from the training texts\n",
        "# Converts the training text into spare matrix of shape (samples, 10000)\n",
        "X_val_vec = vectorizer.transform(X_val)\n",
        "# Transform test data by applying the same vocabulary (from training) to the test set\n",
        "# Ensures that the training and test data have the same structure\n",
        "\n",
        "print(X_train_vec.shape)  # (number_of_samples, 5000)\n",
        "print(X_val_vec.shape)   # (number_of_samples, 5000)\n",
        "# This shows the dimensions of the TF-IDF matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jqHf4MyU5ipN",
        "outputId": "73dd4d40-69ba-4752-a115-074c260cc50e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression\n",
            "Accuracy: 0.6609267814643707\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.6260    0.3418    0.4422      1141\n",
            "           1     0.6240    0.7666    0.6880      3141\n",
            "           2     0.7227    0.6721    0.6965      2861\n",
            "\n",
            "    accuracy                         0.6609      7143\n",
            "   macro avg     0.6576    0.5935    0.6089      7143\n",
            "weighted avg     0.6638    0.6609    0.6521      7143\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Train Logistic Regression model\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression   # Best for binary and multiclass classificaion\n",
        "from sklearn.metrics import classification_report, accuracy_score   # Import evaluation metrics\n",
        "\n",
        "model = LogisticRegression(max_iter=1000)  # max_iter=1000 increases the number of training iterations to help the model converge (default is 100)\n",
        "model.fit(X_train_vec, y_train)\n",
        "\n",
        "# Evaluate lr model\n",
        "\n",
        "y_pred = model.predict(X_val_vec)\n",
        "\n",
        "print(\"Logistic Regression\")\n",
        "print(\"Accuracy:\", accuracy_score(y_val, y_pred))\n",
        "print(classification_report(y_val, y_pred, digits=4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RIMGQpmyBDqE",
        "outputId": "cab2d514-9e1e-45f1-fa61-446edbabd6ca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 2 2 0 2 1 2]\n"
          ]
        }
      ],
      "source": [
        "# Prediction on new unseen data\n",
        "\n",
        "new_tweets = [\"Flight delayed again. Terrible experience.\",\n",
        "              \"Thanks for the great service!\",\n",
        "              \"It was okay, nothing special.\",\n",
        "              \"not sure about what I could say, not bad and not too impressive either\",\n",
        "              \"I wish I could use another classroom\",\n",
        "              \"Mike was gonna come later today, try hold on\",\n",
        "              \"streamlit has their own UI designed already, looks easy to use\"]\n",
        "\n",
        "new_vectorizer = vectorizer.transform(new_tweets)\n",
        "predictions = model.predict(new_vectorizer)\n",
        "\n",
        "print(predictions)  # outputs: [0, 2, 1] or similar\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mHrK2fNt0TMi",
        "outputId": "8d1ae70e-a3ab-48de-afab-d541aa7cf81b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['tweet_eval_vectorizer.pkl']"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ],
      "source": [
        "# Save the model and vectorizer\n",
        "\n",
        "import joblib\n",
        "\n",
        "joblib.dump(model, \"tweet_eval_sentiment_model.pkl\")\n",
        "joblib.dump(vectorizer, \"tweet_eval_vectorizer.pkl\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "files.download(\"tweet_eval_sentiment_model.pkl\")\n",
        "files.download(\"tweet_eval_vectorizer.pkl\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "wBBqo_r0OLMd",
        "outputId": "0437b2fb-945a-40bc-e847-faf2ac19e503"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_4def7e45-8dad-49a4-a184-ee4c6c4964dc\", \"tweet_eval_sentiment_model.pkl\", 240895)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_350f1445-988c-49da-a420-88c752689534\", \"tweet_eval_vectorizer.pkl\", 361009)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qhCRSBna1SLh",
        "outputId": "72af3d6f-b52d-42f8-b487-c4f35470bd86"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Writing clean.py\n"
          ]
        }
      ],
      "source": [
        "# save clean.py file\n",
        "\n",
        "%%writefile clean.py\n",
        "def clean_text(text):\n",
        "    # your cleaning logic here\n",
        "    return cleaned_text\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "qMd3JN_H1cKG",
        "outputId": "6f4ce592-38a7-4f9d-ce9b-05961601fce7"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": [
              "download(\"download_c8b3905c-81bd-4933-918b-4e72b5664a8b\", \"clean.py\", 77)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "files.download(\"clean.py\")"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9b9c8849",
        "outputId": "7c5dd835-1c70-45c1-927e-7fa57485ca29"
      },
      "source": [],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training data shape: (45615, 2)\n",
            "Validation data shape: (2000, 2)\n",
            "Testing data shape: (12284, 2)\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}